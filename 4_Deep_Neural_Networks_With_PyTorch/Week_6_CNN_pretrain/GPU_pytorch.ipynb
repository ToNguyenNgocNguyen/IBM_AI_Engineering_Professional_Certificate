{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Tue_May__3_19:00:59_Pacific_Daylight_Time_2022\n",
      "Cuda compilation tools, release 11.7, V11.7.64\n",
      "Build cuda_11.7.r11.7/compiler.31294372_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jul  9 17:39:29 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 516.01       Driver Version: 516.01       CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   54C    P0    13W /  N/A |      0MiB /  4096MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting environment information...\n",
      "PyTorch version: 2.0.1+cu117\n",
      "Is debug build: False\n",
      "CUDA used to build PyTorch: 11.7\n",
      "ROCM used to build PyTorch: N/A\n",
      "\n",
      "OS: Microsoft Windows 11 Home Single Language\n",
      "GCC version: (tdm64-1) 10.3.0\n",
      "\n",
      "Clang version: Could not collect\n",
      "CMake version: version 3.26.0-rc3\n",
      "Libc version: N/A\n",
      "\n",
      "Python version: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)] (64-bit runtime)\n",
      "Python platform: Windows-10-10.0.22621\n",
      "Is CUDA available: True\n",
      "CUDA runtime version: 11.7.64\n",
      "\n",
      "CUDA_MODULE_LOADING set to: LAZY\n",
      "GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "Nvidia driver version: 516.01\n",
      "cuDNN version: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.7\\bin\\cudnn_ops_train64_8.dll\n",
      "HIP runtime version: N/A\n",
      "MIOpen runtime version: N/A\n",
      "Is XNNPACK available: True\n",
      "\n",
      "CPU:\n",
      "Architecture=9\n",
      "\n",
      "\n",
      "CurrentClockSpeed=2688\n",
      "\n",
      "\n",
      "DeviceID=CPU0\n",
      "\n",
      "\n",
      "Family=205\n",
      "\n",
      "\n",
      "L2CacheSize=7680\n",
      "\n",
      "\n",
      "L2CacheSpeed=\n",
      "\n",
      "\n",
      "Manufacturer=GenuineIntel\n",
      "\n",
      "\n",
      "MaxClockSpeed=2688\n",
      "\n",
      "\n",
      "Name=11th Gen Intel(R) Core(TM) i5-11400H @ 2.70GHz\n",
      "\n",
      "\n",
      "ProcessorType=3\n",
      "\n",
      "\n",
      "Revision=\n",
      "\n",
      "Versions of relevant libraries:\n",
      "[pip3] numpy==1.24.1\n",
      "[pip3] torch==2.0.1+cu117\n",
      "[pip3] torchaudio==2.0.2+cu117\n",
      "[pip3] torchvision==0.15.2+cu117\n",
      "[conda] blas                      1.0                         mkl  \n",
      "[conda] cudatoolkit               11.7.0              h74894db_11    conda-forge\n",
      "[conda] mkl                       2023.1.0         h6a75c08_48682    conda-forge\n",
      "[conda] mkl-service               2.4.0           py310h2bbff1b_1  \n",
      "[conda] numpy                     1.24.1                   pypi_0    pypi\n",
      "[conda] pytorch                   2.0.1           cpu_py310hb0bdfb8_0  \n",
      "[conda] torch                     2.0.1+cu117              pypi_0    pypi\n",
      "[conda] torchaudio                2.0.2+cu117              pypi_0    pypi\n",
      "[conda] torchvision               0.15.2+cu117             pypi_0    pypi\n"
     ]
    }
   ],
   "source": [
    "!python -m torch.utils.collect_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, ConcatDataset, random_split, Dataset, Subset\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm, trange\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.backends.cudnn.enabled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "1\n",
      "0\n",
      "NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformDataset(Dataset):\n",
    "    def __init__(self, subset, transform=None):\n",
    "        super(TransformDataset, self).__init__()\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.subset[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455\n"
     ]
    }
   ],
   "source": [
    "data = datasets.ImageFolder('celeb/')\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_target: {'A': 22, 'B': 82, 'C': 44, 'D': 22, 'E': 47, 'F': 42, 'G': 42, 'H': 38, 'I': 74, 'J': 42}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels, counts = np.unique(data.targets, return_counts=True)\n",
    "print('train_target:', dict(zip(list(data.class_to_idx), counts)))\n",
    "sns.barplot(x=labels, y=counts, saturation=10)\n",
    "sns.set_style('dark')\n",
    "sns.set_theme('talk')\n",
    "plt.xticks(labels, list(data.class_to_idx))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_val_idx, test_idx = train_test_split(range(len(data)), test_size=0.1, stratify=data.targets, shuffle=True)\n",
    "train_val_data = Subset(dataset=data, indices=train_val_idx)\n",
    "test_data = Subset(dataset=data, indices=test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, val_idx = train_test_split(range(len(train_val_data)), test_size=0.1, stratify=list(map(lambda x: data.targets[x], train_val_idx)), shuffle=True)\n",
    "train_data = Subset(dataset=train_val_data, indices=train_idx)\n",
    "val_data = Subset(dataset=train_val_data, indices=val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Upsample(scale=1):\n",
    "    dict_train = dict(zip(*np.unique([train_data[i][1] for i in range(len(train_data))], return_counts=True)))\n",
    "    list_add = []\n",
    "    c_max = max(dict_train.values())\n",
    "    for l, c in dict_train.items():\n",
    "        n_data = scale*c_max - c\n",
    "        count = 0\n",
    "        while count < n_data:\n",
    "            for tup in train_data:\n",
    "                r = np.random.randint(2)\n",
    "                if tup[1] == l and r==0:\n",
    "                    list_add.append(tup)\n",
    "                    count += 1\n",
    "                if count == n_data:\n",
    "                    break\n",
    "    return list_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 67, 1: 67, 2: 67, 3: 67, 4: 67, 5: 67, 6: 67, 7: 67, 8: 67, 9: 67}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data.__add__(Upsample())\n",
    "dict_train = dict(zip(*np.unique([train_data[i][1] for i in range(len(train_data))], return_counts=True)))\n",
    "dict_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_train = transforms.Compose([transforms.Resize((128, 128)), transforms.RandomRotation((-10, 10)), transforms.ToTensor()])\n",
    "transformer_val_test = transforms.Compose([transforms.Resize((128, 128)), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_scale_train = 1\n",
    "up_scale_val = 1\n",
    "up_scale_test = 1\n",
    "\n",
    "train_data = TransformDataset(subset=ConcatDataset([train_data for _ in range(up_scale_train)]), transform=transformer_train)\n",
    "val_data = TransformDataset(subset=ConcatDataset([val_data for _ in range(up_scale_val)]), transform=transformer_val_test)\n",
    "test_data = TransformDataset(subset=ConcatDataset([test_data for _ in range(up_scale_test)]), transform=transformer_val_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 670\n",
      "val: 41\n",
      "test: 46\n",
      "total dataset: 757\n"
     ]
    }
   ],
   "source": [
    "print('train:', len(train_data))\n",
    "print('val:', len(val_data))\n",
    "print('test:', len(test_data))\n",
    "print('total dataset:', len(train_data) + len(val_data) + len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNN(nn.Module):\n",
    "        def __init__(self, in_channel, out_channel, n_classes=10):\n",
    "            super(MyCNN, self).__init__()\n",
    "\n",
    "            self.conv1 = nn.Conv2d(in_channel, 32, 3)\n",
    "            nn.init.kaiming_normal_(self.conv1.weight, nonlinearity='relu')\n",
    "            self.dropout1 = nn.Dropout2d(0.5)\n",
    "\n",
    "            self.batch1 = nn.BatchNorm2d(32)\n",
    "            self.maxpooling1 = nn.MaxPool2d(3)\n",
    "\n",
    "            self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "            nn.init.kaiming_normal_(self.conv2.weight, nonlinearity='relu')\n",
    "            self.dropout2 = nn.Dropout2d(0.5)\n",
    "\n",
    "            self.batch2 = nn.BatchNorm2d(64)\n",
    "            self.maxpooling2 = nn.MaxPool2d(3)\n",
    "\n",
    "            self.fc1 = nn.Linear(out_channel * 13 * 13, n_classes)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.conv1(x))\n",
    "            x = self.dropout1(x)\n",
    "            # print(x.shape)\n",
    "            x = self.batch1(x)\n",
    "            # print(x.shape)\n",
    "            x = self.maxpooling1(x)\n",
    "            # print(x.shape)\n",
    "            x = F.relu(self.conv2(x))\n",
    "            x = self.dropout2(x)\n",
    "            # print(x.shape)\n",
    "            x = self.batch2(x)\n",
    "            # print(x.shape)\n",
    "            x = self.maxpooling2(x)\n",
    "            # print(x.shape)\n",
    "            out = self.fc1(x.view(x.size(0), -1))\n",
    "            # print(out.shape)\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([0.6113], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([5], device='cuda:0'))\n",
      "MyCNN(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout2d(p=0.5, inplace=False)\n",
      "  (batch1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (maxpooling1): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (batch2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (maxpooling2): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=10816, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mycnn = MyCNN(in_channel=3, out_channel=64).to(device)\n",
    "print(torch.max(mycnn(train_data[0][0].reshape(1, 3, 128, 128).to(device)), dim=-1))\n",
    "print(mycnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimzer = optim.Adam(params=mycnn.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def my_train(model, optimizer, criterion, train, val, batch_size, shuffle=True, epochs=1):\n",
    "    trainloader = DataLoader(dataset=train, batch_size=batch_size, shuffle=shuffle)\n",
    "    valloader = DataLoader(dataset=val, batch_size=batch_size, shuffle=shuffle)\n",
    "    batches_per_epoch = len(trainloader)\n",
    "    history = {'train_acc':[],\n",
    "               'train_loss':[],\n",
    "               'val_acc':[]}\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        with trange(batches_per_epoch, unit='batch') as pbar:\n",
    "            pbar.set_description(f'{epoch + 1} epoch(s)')\n",
    "            \n",
    "            # train mode\n",
    "            train_loss = 0\n",
    "            train_acc = 0\n",
    "            model.train()\n",
    "            for x, y in trainloader:\n",
    "                optimizer.zero_grad()\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                yhat = model(x)\n",
    "                _, label = torch.max(yhat, dim=-1)\n",
    "                loss = criterion(yhat, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                train_acc += (label==y).sum().item()\n",
    "                pbar.update()\n",
    "\n",
    "            train_acc = round(train_acc/len(train), 3)\n",
    "            history['train_loss'].append(loss)\n",
    "            history['train_acc'].append(train_acc)\n",
    "\n",
    "            # eval mode\n",
    "            val_acc = 0\n",
    "            model.eval()\n",
    "            for x, y in valloader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                _, label = torch.max(model(x), dim=-1)\n",
    "                val_acc += (label==y).sum().item()\n",
    "\n",
    "            val_acc = val_acc/len(val)\n",
    "            history['val_acc'].append(val_acc)\n",
    "\n",
    "            pbar.set_postfix_str(f'train_loss: {train_loss} train_acc: {train_acc} val_acc: {val_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1 epoch(s): 100%|██████████| 21/21 [00:01<00:00, 14.91batch/s, train_loss: 80.90040326118469 train_acc: 0.201 val_acc: 0.21951219512195122]\n",
      "2 epoch(s): 100%|██████████| 21/21 [00:01<00:00, 20.04batch/s, train_loss: 55.75373411178589 train_acc: 0.382 val_acc: 0.3902439024390244]\n",
      "3 epoch(s): 100%|██████████| 21/21 [00:01<00:00, 19.80batch/s, train_loss: 43.01924967765808 train_acc: 0.479 val_acc: 0.4634146341463415]\n",
      "4 epoch(s): 100%|██████████| 21/21 [00:01<00:00, 20.05batch/s, train_loss: 33.08024334907532 train_acc: 0.585 val_acc: 0.4634146341463415]\n",
      "5 epoch(s): 100%|██████████| 21/21 [00:01<00:00, 20.05batch/s, train_loss: 27.804412007331848 train_acc: 0.633 val_acc: 0.43902439024390244]\n",
      "6 epoch(s): 100%|██████████| 21/21 [00:01<00:00, 20.32batch/s, train_loss: 25.701451361179352 train_acc: 0.657 val_acc: 0.4634146341463415]\n",
      "7 epoch(s): 100%|██████████| 21/21 [00:01<00:00, 20.33batch/s, train_loss: 22.36779636144638 train_acc: 0.699 val_acc: 0.5609756097560976]\n",
      "8 epoch(s): 100%|██████████| 21/21 [00:01<00:00, 20.15batch/s, train_loss: 19.98780408501625 train_acc: 0.728 val_acc: 0.5365853658536586]\n",
      "9 epoch(s): 100%|██████████| 21/21 [00:01<00:00, 20.20batch/s, train_loss: 17.471638649702072 train_acc: 0.73 val_acc: 0.5853658536585366]\n",
      "10 epoch(s): 100%|██████████| 21/21 [00:01<00:00, 20.28batch/s, train_loss: 15.902010023593903 train_acc: 0.758 val_acc: 0.5853658536585366]\n",
      "100%|██████████| 10/10 [00:10<00:00,  1.08s/it]\n"
     ]
    }
   ],
   "source": [
    "my_history = my_train(mycnn, optimzer, criterion, train_data, val_data, batch_size=32, shuffle=True, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = next(iter(DataLoader(dataset=test_data, batch_size=len(test_data), shuffle=True)))\n",
    "X_test = testloader[0].to(device)\n",
    "y_test = testloader[1].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycnn.eval()\n",
    "_, label = torch.max(mycnn(X_test), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 0.5217391304347826\n"
     ]
    }
   ],
   "source": [
    "print('test acc:', (label == y_test).sum().item()/len(y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCNN(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout2d(p=0.5, inplace=False)\n",
      "  (batch1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (maxpooling1): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (batch2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (maxpooling2): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=10816, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(mycnn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyPythonEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
